import torch

def check_cuda():
    """CUDA ë° GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬"""
    
    print("=" * 60)
    print("CUDA & GPU í™•ì¸")
    print("=" * 60)
    
    # PyTorch ë²„ì „
    print(f"\nğŸ“¦ PyTorch ë²„ì „: {torch.__version__}")
    
    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    cuda_available = torch.cuda.is_available()
    print(f"\nğŸ”§ CUDA ì‚¬ìš© ê°€ëŠ¥: {cuda_available}")
    
    if cuda_available:
        # CUDA ë²„ì „
        print(f"ğŸ“Œ CUDA ë²„ì „: {torch.version.cuda}")
        
        # cuDNN ë²„ì „
        print(f"ğŸ“Œ cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
        
        # GPU ê°œìˆ˜
        gpu_count = torch.cuda.device_count()
        print(f"\nğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜: {gpu_count}")
        
        # ê° GPU ì •ë³´
        print("\n" + "=" * 60)
        print("GPU ìƒì„¸ ì •ë³´")
        print("=" * 60)
        for i in range(gpu_count):
            print(f"\n[GPU {i}]")
            print(f"  ì´ë¦„: {torch.cuda.get_device_name(i)}")
            print(f"  ì´ ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
            
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            if torch.cuda.is_initialized():
                allocated = torch.cuda.memory_allocated(i) / 1024**3
                reserved = torch.cuda.memory_reserved(i) / 1024**3
                print(f"  í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated:.2f} GB")
                print(f"  ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {reserved:.2f} GB")
        
        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU
        current_device = torch.cuda.current_device()
        print(f"\nâœ… í˜„ì¬ ê¸°ë³¸ GPU: {current_device} ({torch.cuda.get_device_name(current_device)})")
        
        # ê°„ë‹¨í•œ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸
        print("\n" + "=" * 60)
        print("CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        try:
            x = torch.rand(1000, 1000).cuda()
            y = torch.rand(1000, 1000).cuda()
            z = x @ y
            print("âœ… CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            del x, y, z
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"âŒ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # YOLO í•™ìŠµ ê¶Œì¥ ì„¤ì •
        print("\n" + "=" * 60)
        print("YOLO í•™ìŠµ ê¶Œì¥ ì„¤ì •")
        print("=" * 60)
        print(f"âœ… device=0 (ë˜ëŠ” device={list(range(gpu_count))} for multi-GPU)")
        
        # ë°°ì¹˜ í¬ê¸° ì¶”ì²œ
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if total_memory >= 24:
            print("âœ… batch=32 ì´ìƒ ê°€ëŠ¥ (ëŒ€ìš©ëŸ‰ GPU)")
        elif total_memory >= 12:
            print("âœ… batch=16~32 ê¶Œì¥")
        elif total_memory >= 8:
            print("âœ… batch=8~16 ê¶Œì¥")
        else:
            print("âœ… batch=-1 (ìë™ ì¡°ì •) ë˜ëŠ” batch=4~8 ê¶Œì¥")
            
    else:
        print("\nâŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("âš ï¸  CPU ëª¨ë“œë¡œ í•™ìŠµë©ë‹ˆë‹¤ (ë§¤ìš° ëŠë¦¼)")
        print("\ní•´ê²° ë°©ë²•:")
        print("  1. NVIDIA GPUê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("  2. CUDA Toolkit ì„¤ì¹˜ í™•ì¸")
        print("  3. PyTorch CUDA ë²„ì „ ì¬ì„¤ì¹˜:")
        print("     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        print("\nğŸ’¡ YOLO í•™ìŠµ ì„¤ì •: device='cpu'")
    
    print("\n" + "=" * 60)
    
    return cuda_available


def check_ultralytics_device():
    """Ultralyticsì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ í™•ì¸"""
    try:
        from ultralytics import YOLO
        from ultralytics.utils.torch_utils import select_device
        
        print("\n" + "=" * 60)
        print("Ultralytics ë””ë°”ì´ìŠ¤ í™•ì¸")
        print("=" * 60)
        
        device = select_device('')  # ìë™ ì„ íƒ
        print(f"âœ… Ultralytics ê¸°ë³¸ ë””ë°”ì´ìŠ¤: {device}")
        
    except ImportError:
        print("\nâš ï¸  Ultralyticsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ì„¤ì¹˜: pip install ultralytics")


if __name__ == "__main__":
    # CUDA ì²´í¬
    cuda_available = check_cuda()
    
    # Ultralytics ë””ë°”ì´ìŠ¤ ì²´í¬
    check_ultralytics_device()
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ìµœì¢… ìš”ì•½")
    print("=" * 60)
    if cuda_available:
        print("âœ… GPU í•™ìŠµ ê°€ëŠ¥!")
        print("   YOLO í•™ìŠµ ì‹œ: device=0")
    else:
        print("âŒ CPU í•™ìŠµë§Œ ê°€ëŠ¥")
        print("   YOLO í•™ìŠµ ì‹œ: device='cpu'")
    print("=" * 60)

def check_cuda():
    """CUDA ë° GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬"""
    
    print("=" * 60)
    print("CUDA & GPU í™•ì¸")
    print("=" * 60)
    
    # PyTorch ë²„ì „
    print(f"\nğŸ“¦ PyTorch ë²„ì „: {torch.__version__}")
    
    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    cuda_available = torch.cuda.is_available()
    print(f"\nğŸ”§ CUDA ì‚¬ìš© ê°€ëŠ¥: {cuda_available}")
    
    if cuda_available:
        # CUDA ë²„ì „
        print(f"ğŸ“Œ CUDA ë²„ì „: {torch.version.cuda}")
        
        # cuDNN ë²„ì „
        print(f"ğŸ“Œ cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
        
        # GPU ê°œìˆ˜
        gpu_count = torch.cuda.device_count()
        print(f"\nğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜: {gpu_count}")
        
        # ê° GPU ì •ë³´
        print("\n" + "=" * 60)
        print("GPU ìƒì„¸ ì •ë³´")
        print("=" * 60)
        for i in range(gpu_count):
            print(f"\n[GPU {i}]")
            print(f"  ì´ë¦„: {torch.cuda.get_device_name(i)}")
            print(f"  ì´ ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
            
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            if torch.cuda.is_initialized():
                allocated = torch.cuda.memory_allocated(i) / 1024**3
                reserved = torch.cuda.memory_reserved(i) / 1024**3
                print(f"  í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated:.2f} GB")
                print(f"  ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {reserved:.2f} GB")
        
        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU
        current_device = torch.cuda.current_device()
        print(f"\nâœ… í˜„ì¬ ê¸°ë³¸ GPU: {current_device} ({torch.cuda.get_device_name(current_device)})")
        
        # ê°„ë‹¨í•œ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸
        print("\n" + "=" * 60)
        print("CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        try:
            x = torch.rand(1000, 1000).cuda()
            y = torch.rand(1000, 1000).cuda()
            z = x @ y
            print("âœ… CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            del x, y, z
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"âŒ CUDA ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # YOLO í•™ìŠµ ê¶Œì¥ ì„¤ì •
        print("\n" + "=" * 60)
        print("YOLO í•™ìŠµ ê¶Œì¥ ì„¤ì •")
        print("=" * 60)
        print(f"âœ… device=0 (ë˜ëŠ” device={list(range(gpu_count))} for multi-GPU)")
        
        # ë°°ì¹˜ í¬ê¸° ì¶”ì²œ
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if total_memory >= 24:
            print("âœ… batch=32 ì´ìƒ ê°€ëŠ¥ (ëŒ€ìš©ëŸ‰ GPU)")
        elif total_memory >= 12:
            print("âœ… batch=16~32 ê¶Œì¥")
        elif total_memory >= 8:
            print("âœ… batch=8~16 ê¶Œì¥")
        else:
            print("âœ… batch=-1 (ìë™ ì¡°ì •) ë˜ëŠ” batch=4~8 ê¶Œì¥")
            
    else:
        print("\nâŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("âš ï¸  CPU ëª¨ë“œë¡œ í•™ìŠµë©ë‹ˆë‹¤ (ë§¤ìš° ëŠë¦¼)")
        print("\ní•´ê²° ë°©ë²•:")
        print("  1. NVIDIA GPUê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("  2. CUDA Toolkit ì„¤ì¹˜ í™•ì¸")
        print("  3. PyTorch CUDA ë²„ì „ ì¬ì„¤ì¹˜:")
        print("     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        print("\nğŸ’¡ YOLO í•™ìŠµ ì„¤ì •: device='cpu'")
    
    print("\n" + "=" * 60)
    
    return cuda_available


def check_ultralytics_device():
    """Ultralyticsì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ í™•ì¸"""
    try:
        from ultralytics import YOLO
        from ultralytics.utils.torch_utils import select_device
        
        print("\n" + "=" * 60)
        print("Ultralytics ë””ë°”ì´ìŠ¤ í™•ì¸")
        print("=" * 60)
        
        device = select_device('')  # ìë™ ì„ íƒ
        print(f"âœ… Ultralytics ê¸°ë³¸ ë””ë°”ì´ìŠ¤: {device}")
        
    except ImportError:
        print("\nâš ï¸  Ultralyticsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ì„¤ì¹˜: pip install ultralytics")


if __name__ == "__main__":
    # CUDA ì²´í¬
    cuda_available = check_cuda()
    
    # Ultralytics ë””ë°”ì´ìŠ¤ ì²´í¬
    check_ultralytics_device()
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ìµœì¢… ìš”ì•½")
    print("=" * 60)
    if cuda_available:
        print("âœ… GPU í•™ìŠµ ê°€ëŠ¥!")
        print("   YOLO í•™ìŠµ ì‹œ: device=0")
    else:
        print("âŒ CPU í•™ìŠµë§Œ ê°€ëŠ¥")
        print("   YOLO í•™ìŠµ ì‹œ: device='cpu'")
    print("=" * 60)