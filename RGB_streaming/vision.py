import cv2
import numpy as np
from ultralytics import YOLO
import torch
from pypylon import pylon
import time
from collections import defaultdict
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
import json
import os

def load_yolov11(model_path):
    """YOLOv11 ëª¨ë¸ ë¡œë“œ (GPU ìš°ì„ )"""
    try:
        # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"PyTorch ë²„ì „: {torch.__version__}")
        print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"GPU ì¥ì¹˜: {torch.cuda.get_device_name(0)}")
            print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        
        # YOLOv11 ëª¨ë¸ ë¡œë“œ
        print(f"\nYOLOv11 ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
        model = YOLO(model_path)
        
        # GPUë¡œ ëª¨ë¸ ì´ë™
        model.to(device)
        
        print(f"âœ… YOLOv11 ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        print(f"ğŸ® ì‚¬ìš© ì¥ì¹˜: {device.upper()}")
        
        return model, device
        
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

@dataclass
class DetectedObject:
    """ê°ì§€ëœ íí”Œë¼ìŠ¤í‹± ê°ì²´ ì •ë³´"""
    id: int
    class_name: str
    center: Tuple[int, int]
    bbox: Tuple[int, int, int, int]
    confidence: float
    metainfo: Optional[Dict] = None

class PlasticClassifier:
    """AI Hub íí”Œë¼ìŠ¤í‹± 4ì¢… ë¶„ë¥˜ê¸°"""
    
    PLASTIC_CLASSES = {
        'PET': 'í´ë¦¬ì—í‹¸ë Œ í…Œë ˆí”„íƒˆë ˆì´íŠ¸',
        'PE': 'í´ë¦¬ì—í‹¸ë Œ',
        'PP': 'í´ë¦¬í”„ë¡œí•„ë Œ',
        'PS': 'í´ë¦¬ìŠ¤í‹°ë Œ'
    }
    
    @classmethod
    def get_plastic_info(cls, class_name: str) -> str:
        return cls.PLASTIC_CLASSES.get(class_name, 'ì•Œ ìˆ˜ ì—†ëŠ” í”Œë¼ìŠ¤í‹±')
    
    @classmethod
    def parse_metainfo(cls, metainfo_name: str) -> Dict:
        try:
            parts = metainfo_name.split('_')
            return {
                'container_type': parts[0] if len(parts) > 0 else 'ê¸°íƒ€',
                'transparency': parts[1] if len(parts) > 1 else 'ë¶ˆíˆ¬ëª…',
                'shape': parts[2] if len(parts) > 2 else 'ê¸°íƒ€',
                'size': parts[3] if len(parts) > 3 else 'ê¸°íƒ€',
                'compression': parts[4] if len(parts) > 4 else 'ë¹„ì••ì¶•'
            }
        except:
            return {'container_type': 'ê¸°íƒ€', 'transparency': 'ë¶ˆíˆ¬ëª…', 'shape': 'ê¸°íƒ€', 'size': 'ê¸°íƒ€', 'compression': 'ë¹„ì••ì¶•'}

class LineCounter:
    """ì»¨ë² ì´ì–´ ë²¨íŠ¸ ìŠ¤íƒ€ì¼ ì¹´ìš´íŒ… ë¼ì¸"""
    
    def __init__(self, line_start: Tuple[int, int], line_end: Tuple[int, int], 
                 thickness: int = 3, buffer_zone: int = 50):
        self.line_start = line_start
        self.line_end = line_end
        self.thickness = thickness
        self.buffer_zone = buffer_zone
        self.tracked_objects = {}
        self.crossed_objects = set()
        
        self.class_counts = {
            'PET': 0, 'PE': 0, 'PP': 0, 'PS': 0
        }
        self.detailed_stats = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
        
    def is_line_crossed(self, obj_id: int, center: Tuple[int, int]) -> bool:
        x, y = center
        dx = self.line_end[0] - self.line_start[0]
        dy = self.line_end[1] - self.line_start[1]
        
        if dx == 0 and dy == 0:
            distance = np.sqrt((x - self.line_start[0])**2 + (y - self.line_start[1])**2)
        else:
            distance = abs(dy * x - dx * y + self.line_end[0] * self.line_start[1] - 
                          self.line_end[1] * self.line_start[0]) / np.sqrt(dx**2 + dy**2)
        
        current_side = self._get_side_of_line(center)
        
        if obj_id in self.tracked_objects:
            previous_side = self.tracked_objects[obj_id]['side']
            if (previous_side != current_side and 
                distance < self.buffer_zone and 
                obj_id not in self.crossed_objects):
                self.crossed_objects.add(obj_id)
                return True
        
        self.tracked_objects[obj_id] = {
            'side': current_side,
            'center': center,
            'last_seen': time.time()
        }
        return False
    
    def _get_side_of_line(self, point: Tuple[int, int]) -> int:
        x, y = point
        return np.sign((self.line_end[0] - self.line_start[0]) * (y - self.line_start[1]) - 
                      (self.line_end[1] - self.line_start[1]) * (x - self.line_start[0]))
    
    def update_stats(self, class_name: str, metainfo: Dict = None):
        if class_name in self.class_counts:
            self.class_counts[class_name] += 1
            if metainfo:
                self.detailed_stats[class_name]['transparency'][metainfo.get('transparency', 'ë¶ˆíˆ¬ëª…')] += 1
                self.detailed_stats[class_name]['shape'][metainfo.get('shape', 'ê¸°íƒ€')] += 1
    
    def cleanup_old_tracks(self, timeout: int = 5):
        current_time = time.time()
        to_remove = [obj_id for obj_id, data in self.tracked_objects.items() 
                     if current_time - data['last_seen'] > timeout]
        for obj_id in to_remove:
            del self.tracked_objects[obj_id]
            self.crossed_objects.discard(obj_id)
    
    def draw_line(self, frame: np.ndarray) -> np.ndarray:
        cv2.line(frame, self.line_start, self.line_end, (0, 255, 0), self.thickness)
        mid_point = ((self.line_start[0] + self.line_end[0]) // 2,
                     (self.line_start[1] + self.line_end[1]) // 2)
        cv2.putText(frame, "CONVEYOR COUNTING LINE", (mid_point[0] - 80, mid_point[1] - 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        return frame

class PlasticSortingSystem:
    """AI Hub íí”Œë¼ìŠ¤í‹± ìë™ ì„ ë³„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.sorting_actions = {
            'PET': self.handle_pet,
            'PE': self.handle_pe,
            'PP': self.handle_pp,
            'PS': self.handle_ps
        }
        self.sorting_log = []
        self.bins = {
            'PET': {'count': 0, 'bin_id': 'A', 'color': (0, 165, 255)},
            'PE': {'count': 0, 'bin_id': 'B', 'color': (255, 0, 0)},
            'PP': {'count': 0, 'bin_id': 'C', 'color': (0, 255, 0)},
            'PS': {'count': 0, 'bin_id': 'D', 'color': (255, 0, 255)}
        }
    
    def execute_sorting(self, class_name: str, metainfo: Dict = None):
        if class_name in self.sorting_actions:
            self.sorting_actions[class_name](metainfo)
        else:
            self.handle_unknown(class_name, metainfo)
    
    def handle_pet(self, metainfo: Dict = None):
        self.bins['PET']['count'] += 1
    
    def handle_pe(self, metainfo: Dict = None):
        self.bins['PE']['count'] += 1
    
    def handle_pp(self, metainfo: Dict = None):
        self.bins['PP']['count'] += 1
    
    def handle_ps(self, metainfo: Dict = None):
        self.bins['PS']['count'] += 1
    
    def handle_unknown(self, class_name: str, metainfo: Dict = None):
        pass

class BaslerCameraManager:
    """Basler ì‚°ì—…ìš© ì¹´ë©”ë¼ ê´€ë¦¬"""
    
    def __init__(self, camera_index: int = 0):
        self.camera = None
        self.converter = None
        self.camera_index = camera_index
        self.is_connected = False
    
    def initialize(self, camera_ip: str = None) -> bool:
        try:
            tlFactory = pylon.TlFactory.GetInstance()
            
            if camera_ip:
                device_info = pylon.DeviceInfo()
                device_info.SetIpAddress(camera_ip)
                self.camera = pylon.InstantCamera(tlFactory.CreateDevice(device_info))
            else:
                devices = tlFactory.EnumerateDevices()
                if not devices:
                    return False
                if self.camera_index >= len(devices):
                    return False
                self.camera = pylon.InstantCamera(tlFactory.CreateDevice(devices[self.camera_index]))
            
            self.camera.Open()
            self.setup_camera_parameters()
            
            self.converter = pylon.ImageFormatConverter()
            self.converter.OutputPixelFormat = pylon.PixelType_BGR8packed
            self.converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned
            
            self.is_connected = True
            print(f"Basler ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
            return True
        except Exception as e:
            print(f"ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def setup_camera_parameters(self):
        """ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ì„¤ì • - FPS ìµœì í™”"""
        try:
            print("\nğŸ“· Basler ì¹´ë©”ë¼ ì„¤ì • ì‹œì‘...")
            
            # 1. ë²„í¼ ì„¤ì •
            self.camera.MaxNumBuffer.Value = 5
            print("  âœ“ ë²„í¼ í¬ê¸°: 5")
            
            # 2. í•´ìƒë„ ì„¤ì •
            max_width = self.camera.Width.Max
            max_height = self.camera.Height.Max
            target_width = min(1280, max_width)
            target_height = min(720, max_height)
            
            self.camera.Width.Value = target_width
            self.camera.Height.Value = target_height
            print(f"  âœ“ í•´ìƒë„: {target_width}x{target_height}")
            
            # 3. ExposureAuto ë„ê¸° (ë§¤ìš° ì¤‘ìš”!)
            try:
                if hasattr(self.camera, 'ExposureAuto'):
                    self.camera.ExposureAuto.SetValue('Off')
                    print(f"  âœ“ ìë™ ë…¸ì¶œ: Off")
            except Exception as e:
                print(f"  âš  ìë™ ë…¸ì¶œ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 4. ExposureTime ì„¤ì • (FPSì˜ í•µì‹¬!)
            try:
                if hasattr(self.camera, 'ExposureTime'):
                    # í˜„ì¬ ë…¸ì¶œ ì‹œê°„ í™•ì¸
                    current_exposure = self.camera.ExposureTime.GetValue()
                    print(f"  â€¢ í˜„ì¬ ë…¸ì¶œ ì‹œê°„: {current_exposure:.0f}Î¼s ({1000000/current_exposure:.1f} fps ì œí•œ)")
                    
                    # ëª©í‘œ: 10ms (10000Î¼s) = ìµœëŒ€ 100fps ê°€ëŠ¥
                    target_exposure = 10000
                    
                    # ë²”ìœ„ í™•ì¸
                    min_exposure = self.camera.ExposureTime.Min
                    max_exposure = self.camera.ExposureTime.Max
                    
                    # ì•ˆì „í•œ ê°’ìœ¼ë¡œ ì„¤ì •
                    new_exposure = max(min_exposure, min(target_exposure, max_exposure))
                    self.camera.ExposureTime.SetValue(new_exposure)
                    
                    actual_exposure = self.camera.ExposureTime.GetValue()
                    max_fps = 1000000 / actual_exposure
                    print(f"  âœ“ ìƒˆ ë…¸ì¶œ ì‹œê°„: {actual_exposure:.0f}Î¼s (ìµœëŒ€ {max_fps:.1f} fps)")
            except Exception as e:
                print(f"  âš  ë…¸ì¶œ ì‹œê°„ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 5. GainAuto ë„ê¸°
            try:
                if hasattr(self.camera, 'GainAuto'):
                    self.camera.GainAuto.SetValue('Off')
                    print(f"  âœ“ ìë™ ê²Œì¸: Off")
            except Exception as e:
                print(f"  âš  ìë™ ê²Œì¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 6. TriggerMode ë„ê¸° (ì¤‘ìš”!)
            try:
                if hasattr(self.camera, 'TriggerMode'):
                    self.camera.TriggerMode.SetValue('Off')
                    print(f"  âœ“ íŠ¸ë¦¬ê±° ëª¨ë“œ: Off")
            except Exception as e:
                print(f"  âš  íŠ¸ë¦¬ê±° ëª¨ë“œ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 7. Acquisition Mode ì„¤ì •
            try:
                if hasattr(self.camera, 'AcquisitionMode'):
                    self.camera.AcquisitionMode.SetValue('Continuous')
                    print(f"  âœ“ Acquisition Mode: Continuous")
            except Exception as e:
                print(f"  âš  Acquisition ëª¨ë“œ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            print("ğŸ“· ì¹´ë©”ë¼ ì„¤ì • ì™„ë£Œ!\n")
            
        except Exception as e:
            print(f"âŒ ì¹´ë©”ë¼ ì„¤ì • ì˜¤ë¥˜: {e}")
    
    def grab_frame(self) -> Optional[np.ndarray]:
        if not self.is_connected or not self.camera:
            return None
        try:
            if self.camera and self.camera.IsGrabbing():
                grabResult = self.camera.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)
                if grabResult.GrabSucceeded():
                    image = self.converter.Convert(grabResult)
                    frame = image.GetArray()
                    grabResult.Release()
                    return frame
                else:
                    grabResult.Release()
        except Exception as e:
            print(f"í”„ë ˆì„ ìº¡ì²˜ ì˜¤ë¥˜: {e}")
        return None
    
    def start_grabbing(self):
        if self.camera and self.is_connected:
            self.camera.StartGrabbing(pylon.GrabStrategy_LatestImageOnly)
    
    def stop_grabbing(self):
        if self.camera and self.is_connected:
            self.camera.StopGrabbing()
    
    def close(self):
        try:
            if self.camera and self.camera.IsOpen():
                if self.camera.IsGrabbing():
                    self.camera.StopGrabbing()
                self.camera.Close()
            self.is_connected = False
        except Exception as e:
            print(f"ì¹´ë©”ë¼ í•´ì œ ì˜¤ë¥˜: {e}")

class AIHubPlasticDetectionSystem:
    """YOLOv11 ê¸°ë°˜ AI Hub íí”Œë¼ìŠ¤í‹± ê°ì§€ ì‹œìŠ¤í…œ (GPU ê°€ì†)"""
    
    CLASS_NAMES = ['PET', 'PS', 'PP', 'PE']
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.7, img_size: int = 640):
        self.model, self.device = load_yolov11(model_path)
        if self.model is None:
            raise RuntimeError("YOLOv11 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        
        self.confidence_threshold = confidence_threshold
        self.img_size = img_size
        self.camera_manager = BaslerCameraManager()
        self.line_counter = None
        self.sorting_system = PlasticSortingSystem()
        
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0
        self.total_processed = 0
        
        # ëª¨ë¸ ì›Œë°ì—…
        print("ëª¨ë¸ ì›Œë°ì—… ì¤‘...")
        dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)
        for _ in range(3):
            _ = self.model.predict(dummy_img, verbose=False, device=self.device, imgsz=self.img_size)
        print("ì›Œë°ì—… ì™„ë£Œ!")
        
        # ëª¨ë¸ í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸°
        if hasattr(self.model, 'names'):
            self.CLASS_NAMES = [self.model.names[i].upper() for i in range(len(self.model.names))]
            print(f"ëª¨ë¸ í´ë˜ìŠ¤: {self.CLASS_NAMES}")
    
    def detect(self, frame: np.ndarray) -> List[DetectedObject]:
        """YOLOv11ì„ ì‚¬ìš©í•œ ê°ì²´ ê°ì§€ + ì¶”ì  (GPU ê°€ì†)"""
        try:
            # YOLOv11 ì¶”ë¡  + ì¶”ì 
            results = self.model.track(  # â† predict â†’ track ë³€ê²½!
                source=frame,
                conf=self.confidence_threshold,
                imgsz=self.img_size,
                device=self.device,
                verbose=False,
                half=True,  # FP16
                max_det=100,
                persist=True,  # â† ì¶”ì  ID ìœ ì§€ (ì¤‘ìš”!)
                tracker="bytetrack.yaml"  # ë˜ëŠ” "botsort.yaml"
            )
            
            detected_objects = []
            
            # ê²°ê³¼ íŒŒì‹±
            for result in results:
                boxes = result.boxes
                
                if boxes is None or len(boxes) == 0:
                    continue
                
                # ID í™•ì¸ (tracking ì‹¤íŒ¨ ì‹œ Noneì¼ ìˆ˜ ìˆìŒ)
                if boxes.id is None:
                    # print("âš ï¸ Tracking IDê°€ ì—†ìŠµë‹ˆë‹¤. predict ëª¨ë“œë¡œ fallback")
                    # Tracking ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                    xyxy = boxes.xyxy.cpu().numpy()
                    conf = boxes.conf.cpu().numpy()
                    cls = boxes.cls.cpu().numpy().astype(int)
                    
                    for idx, (box, confidence, class_id) in enumerate(zip(xyxy, conf, cls)):
                        if class_id >= len(self.CLASS_NAMES):
                            continue
                        
                        class_name = self.CLASS_NAMES[class_id]
                        x1, y1, x2, y2 = map(int, box)
                        center_x = (x1 + x2) // 2
                        center_y = (y1 + y2) // 2
                        
                        detected_obj = DetectedObject(
                            id=idx,
                            class_name=class_name,
                            center=(center_x, center_y),
                            bbox=(x1, y1, x2, y2),
                            confidence=float(confidence)
                        )
                        detected_objects.append(detected_obj)
                    continue
                
                # ë°°ì¹˜ ì²˜ë¦¬ (tracking ID í¬í•¨)
                xyxy = boxes.xyxy.cpu().numpy()
                conf = boxes.conf.cpu().numpy()
                cls = boxes.cls.cpu().numpy().astype(int)
                track_ids = boxes.id.cpu().numpy().astype(int)  # â† ê³ ìœ  ì¶”ì  ID!
                
                for box, confidence, class_id, track_id in zip(xyxy, conf, cls, track_ids):
                    if class_id >= len(self.CLASS_NAMES):
                        continue
                    
                    class_name = self.CLASS_NAMES[class_id]
                    x1, y1, x2, y2 = map(int, box)
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2
                    
                    detected_obj = DetectedObject(
                        id=int(track_id),  # â† ì´ì œ ê³ ìœ í•œ ì¶”ì  ID!
                        class_name=class_name,
                        center=(center_x, center_y),
                        bbox=(x1, y1, x2, y2),
                        confidence=float(confidence)
                    )
                    detected_objects.append(detected_obj)
            
            return detected_objects
            
        except Exception as e:
            print(f"ê°ì§€ ì˜¤ë¥˜: {e}")
            return []
    
    def setup_conveyor_line(self, frame_shape: Tuple[int, int]):
        """ì»¨ë² ì´ì–´ ë¼ì¸ ì„¤ì •"""
        height, width = frame_shape[:2]
        line_start = (width // 2, height // 4)
        line_end = (width // 2, 6 * height // 4)
        self.line_counter = LineCounter(line_start, line_end, buffer_zone=60)
    
    def draw_detections(self, frame: np.ndarray, detected_objects: List[DetectedObject]) -> np.ndarray:
        """ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°"""
        class_colors = {
            'PET': (0, 165, 255),
            'PE': (255, 0, 0),
            'PP': (0, 255, 0),
            'PS': (255, 0, 255)
        }
        
        for obj in detected_objects:
            x1, y1, x2, y2 = obj.bbox
            color = class_colors.get(obj.class_name, (128, 128, 128))
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.circle(frame, obj.center, 5, (0, 0, 255), -1)
            
            label = f"{obj.class_name}: {obj.confidence:.2f}"
            cv2.putText(frame, label, (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        return frame
    
    def draw_ui(self, frame: np.ndarray) -> np.ndarray:
        """UI ê·¸ë¦¬ê¸°"""
        height, width = frame.shape[:2]
        
        self.fps_counter += 1
        if time.time() - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_counter
            self.fps_counter = 0
            self.fps_start_time = time.time()
        
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (500, 180), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        
        device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU"
        cv2.putText(frame, f"YOLOv11 Plastic Detection ({device_name})", (10, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        cv2.putText(frame, f"FPS: {self.current_fps} | Total: {self.total_processed}", 
                   (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        y_offset = 75
        if self.line_counter:
            for class_name, count in self.line_counter.class_counts.items():
                color = self.sorting_system.bins[class_name]['color']
                bin_id = self.sorting_system.bins[class_name]['bin_id']
                cv2.putText(frame, f"{class_name}({bin_id}): {count}", 
                           (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                y_offset += 25
        
        cv2.putText(frame, "Press 'q':Quit | 'r':Reset | 's':Stats", 
                   (10, height - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        return frame
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        print("AI Hub íí”Œë¼ìŠ¤í‹± ê°ì§€ ì‹œìŠ¤í…œ ì‹œì‘ (YOLOv11 + GPU)")
        
        # íƒ€ì´ë° ì¸¡ì •ìš©
        timing_grab = []
        timing_inference = []
        timing_draw = []
        timing_total = []
        
        camera_ip = None
        if not self.camera_manager.initialize(camera_ip=camera_ip):
            print("Basler ì¹´ë©”ë¼ ì‹¤íŒ¨. ì›¹ìº  ì‚¬ìš©")
            
            cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
            
            if not cap.isOpened():
                print("ì¹´ë©”ë¼ ì¸ë±ìŠ¤ 0 ì‹¤íŒ¨, ì¸ë±ìŠ¤ 1 ì‹œë„...")
                cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)
            
            if not cap.isOpened():
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            cap.set(cv2.CAP_PROP_FPS, 60)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            actual_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
            actual_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
            actual_fps = cap.get(cv2.CAP_PROP_FPS)
            print(f"ì¹´ë©”ë¼ ì„¤ì •: {actual_width}x{actual_height} @ {actual_fps}fps")
            
            use_basler = False
        else:
            self.camera_manager.start_grabbing()
            use_basler = True
        
        try:
            print("ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. íí”Œë¼ìŠ¤í‹± ê°ì§€ ì‹œì‘...")
            print("íƒ€ì´ë° ì¸¡ì • í™œì„±í™” - 100 í”„ë ˆì„ í›„ í†µê³„ ì¶œë ¥\n")
            
            frame_count = 0
            
            while True:
                t_total_start = time.time()
                
                # 1. í”„ë ˆì„ íšë“ ì‹œê°„
                t1 = time.time()
                if use_basler:
                    frame = self.camera_manager.grab_frame()
                    if frame is None:
                        continue
                else:
                    ret, frame = cap.read()
                    if not ret:
                        break
                t2 = time.time()
                timing_grab.append((t2 - t1) * 1000)
                
                if self.line_counter is None:
                    self.setup_conveyor_line(frame.shape)
                
                # 2. ì¶”ë¡  ì‹œê°„
                t3 = time.time()
                detected_objects = self.detect(frame)
                t4 = time.time()
                timing_inference.append((t4 - t3) * 1000)
                
                # ë¼ì¸ í¬ë¡œì‹± ì²´í¬
                for obj in detected_objects:
                    if self.line_counter.is_line_crossed(obj.id, obj.center):
                        metainfo = PlasticClassifier.parse_metainfo("ê¸°ë³¸_íˆ¬ëª…_ë³‘ë¥˜_ëŒ€_ë¹„ì••ì¶•")
                        self.line_counter.update_stats(obj.class_name, metainfo)
                        self.sorting_system.execute_sorting(obj.class_name, metainfo)
                        self.total_processed += 1
                
                # 30í”„ë ˆì„ë§ˆë‹¤ ì •ë¦¬
                frame_count += 1
                if frame_count % 30 == 0:
                    self.line_counter.cleanup_old_tracks()
                
                # 3. ê·¸ë¦¬ê¸° ì‹œê°„
                t5 = time.time()
                frame = self.draw_detections(frame, detected_objects)
                frame = self.line_counter.draw_line(frame)
                frame = self.draw_ui(frame)
                
                cv2.imshow('YOLOv11 Plastic Detection', frame)
                cv2.waitKey(1)
                t6 = time.time()
                timing_draw.append((t6 - t5) * 1000)
                
                timing_total.append((time.time() - t_total_start) * 1000)
                
                # 100í”„ë ˆì„ë§ˆë‹¤ íƒ€ì´ë° í†µê³„ ì¶œë ¥
                if frame_count == 100:
                    print("\n" + "="*70)
                    print("â±ï¸  íƒ€ì´ë° ë¶„ì„ (100 í”„ë ˆì„ í‰ê· )")
                    print("="*70)
                    print(f"{'êµ¬ê°„':<20} {'í‰ê· (ms)':<15} {'ì˜ˆìƒ FPS':<15}")
                    print("-"*70)
                    print(f"{'í”„ë ˆì„ íšë“':<20} {np.mean(timing_grab):>10.2f}ms    {1000/np.mean(timing_grab):>10.1f} fps")
                    print(f"{'ì¶”ë¡ ':<20} {np.mean(timing_inference):>10.2f}ms    {1000/np.mean(timing_inference):>10.1f} fps")
                    print(f"{'ê·¸ë¦¬ê¸°+í‘œì‹œ':<20} {np.mean(timing_draw):>10.2f}ms    {1000/np.mean(timing_draw):>10.1f} fps")
                    print(f"{'ì „ì²´':<20} {np.mean(timing_total):>10.2f}ms    {1000/np.mean(timing_total):>10.1f} fps")
                    print("="*70)
                    
                    # ë³‘ëª© ì§„ë‹¨
                    grab_avg = np.mean(timing_grab)
                    if grab_avg > 50:
                        print(f"âš ï¸  ë³‘ëª©: í”„ë ˆì„ íšë“ ({grab_avg:.1f}ms)")
                        print("   â†’ Basler ì¹´ë©”ë¼ FPS ì„¤ì • í™•ì¸ í•„ìš”")
                        print("   â†’ Pylon Viewerë¡œ ì¹´ë©”ë¼ FPS ì„¤ì • í™•ì¸")
                    
                    # íƒ€ì´ë° ë¦¬ì…‹
                    timing_grab.clear()
                    timing_inference.clear()
                    timing_draw.clear()
                    timing_total.clear()
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):
                    self.line_counter.class_counts = {'PET': 0, 'PE': 0, 'PP': 0, 'PS': 0}
                    self.line_counter.crossed_objects.clear()
                    for bin_info in self.sorting_system.bins.values():
                        bin_info['count'] = 0
                    self.sorting_system.sorting_log.clear()
                    self.total_processed = 0
                elif key == ord('s'):
                    self.print_statistics()
        
        except KeyboardInterrupt:
            print("\nì‹œìŠ¤í…œ ì¤‘ë‹¨")
        except Exception as e:
            print(f"\nì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        finally:
            if use_basler:
                self.camera_manager.stop_grabbing()
                self.camera_manager.close()
            else:
                cap.release()
            cv2.destroyAllWindows()
    
    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "="*60)
        print("AI Hub íí”Œë¼ìŠ¤í‹± ê°ì§€ ì‹œìŠ¤í…œ í†µê³„")
        print("="*60)
        total_count = sum(self.line_counter.class_counts.values())
        print(f"ì´ ì²˜ë¦¬ëŸ‰: {total_count}ê°œ")
        print(f"í˜„ì¬ FPS: {self.current_fps}")
        print(f"ì‚¬ìš© ì¥ì¹˜: {self.device.upper()}")
        if torch.cuda.is_available():
            print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB")

if __name__ == "__main__":
    print("AI Hub íí”Œë¼ìŠ¤í‹± ê°ì§€ ì‹œìŠ¤í…œ v4.0 (YOLOv11 + GPU)")
    
    model_path = "C:/Users/USER/Desktop/ê¸°ì¡´íŒŒì¼ë°±ì—…/RTC2PLC/prototype/runs/detect/plastic_detector4/weights/best.pt"
    
    if not os.path.exists(model_path):
        print(f"\nâŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        exit(1)
    
    try:
        detector = AIHubPlasticDetectionSystem(
            model_path=model_path,
            confidence_threshold=0.7,
            img_size=640  # ë” ë¹ ë¥´ê²Œ: 480 ë˜ëŠ” 320
        )
        detector.run()
    except Exception as e:
        print(f"\nì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()